\documentclass[11pt]{article}
\usepackage{inputenc}
\usepackage{comment}
\usepackage{fontspec}
\usepackage{authblk}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{gensymb}
\usepackage{float}
\usepackage{enumerate}
\usepackage{tocloft}
\usepackage{abstract}
\usepackage[hidelinks]{hyperref}
\usepackage{appendix}
\usepackage[dvipsnames, svgnames, x11names]{xcolor}
\usepackage{dirtree}
\usepackage{cite}
\usepackage{geometry}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subfig}
% \usepackage[hmargin={3.18cm, 3.18cm}, width=14.64cm, vmargin={2.54cm, 2.54cm}, height=24.62cm]{geometry}
\usepackage[ruled]{algorithm2e}
\usepackage{indentfirst}
\usepackage{unicode-math}

\setlength{\headheight}{16pt}

\setmainfont[%
ItalicFont=NewCM10-Italic.otf,%
BoldFont=NewCM10-Bold.otf,%
BoldItalicFont=NewCM10-BoldItalic.otf,%
SmallCapsFeatures={Numbers=OldStyle}]{NewCM10-Regular.otf}

\setsansfont[%
ItalicFont=NewCMSans10-Oblique.otf,%
BoldFont=NewCMSans10-Bold.otf,%
BoldItalicFont=NewCMSans10-BoldOblique.otf,%
SmallCapsFeatures={Numbers=OldStyle}]{NewCMSans10-Regular.otf}

\setmonofont[ItalicFont=NewCMMono10-Italic.otf,%
BoldFont=NewCMMono10-Bold.otf,%
BoldItalicFont=NewCMMono10-BoldOblique.otf,%
SmallCapsFeatures={Numbers=OldStyle}]{NewCMMono10-Regular.otf}

\setmathfont{NewCMMath-Regular.otf}

% \setsize

% \setlength{\parindent}{2em}

\pagestyle{fancy}

\renewcommand\thesection{\arabic{section}}

\newcommand*{\rmd}{\mathop{}\!\mathrm{d}}
\newcommand*{\sgn}{\mathrm{sgn}}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}

\title{\Huge Gender classification via functional connectivity}

\author{
    \parbox{0.2\textwidth}{
        \centering GUO Siye \\
        \centering 24112709G
    }
    \parbox{0.2\textwidth}{
        \centering LIU Chang \\
        \centering 24116156G
    }
    \parbox{0.2\textwidth}{
        \centering WANG Zeyu \\
        \centering 24056788G
    }
    \parbox{0.2\textwidth}{
        \centering ZHANG Qidan \\
        \centering 24126201G
    }
}

\date{\today}

\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{3}

\begin{document}

\maketitle

\begin{abstract}
    Gender difference in the brain has been an important research direction in neuroscience, and in recent years there are a large number of existing studies about gender classification based on machine learning methods and functional connectivity. However, most of these models are highly nonlinear (e.g. RNN), which leads to a poor explainability. For this reason, we designed and implemented a model based on multiple hyperplanes, which can reach a higher explainability, based on SVM, CNN and other algorithms. We tested the model with functional connectivity data computed from the Human Connectome Project (HCP) dataset. The results show that our method can also achieve similar or even higher accuracy and AUC. Meanwhile, based on the obtained model and the existing studies on brain region in neuroscience, we found that the gender differences of the resting state functional connectivity are mainly reflected in the frontal lobe and parietal lobe.
    \\\\
    \textbf{Keywords:} resting-state fMRI, gender, classification, machine learning, deep learning, human connectome project.
\end{abstract}


\newpage

\tableofcontents
\thispagestyle{empty}
\setcounter{page}{0}

\newpage

\section{Introduction}

\subsection{Gender differences in brain connectivity}

Gender differences in brain network is an important concern of neuroscience and psychology. It has been proved that there exists gender differences for structure connectivity or brain image\cite{Gong2009-gu}\cite{Dibaji2023-bn}\cite{Ebel2023-pu} with the following facts: (1) Women showed greater overall cortical connectivity and the underlying organization of their cortical networks was more efficient compared with men; (2) Gender differences may be reflected in anatomical structures. In the meanwhile, there are many researches show that the gender differences exist in emotion\cite{chaplin2013gender}\cite{fischer2018gender}, memory\cite{guillem2005gender}, perception \cite{skaalvik1994gender}\cite{soetanto2006there}\cite{wiesenfeld2005sex}, and some disease \cite{Sendi2023-nu}\cite{Yan2019-yc}. .

However, most of these studies only proves that the gender differences exists in structure or in task state. Thus, in order to find some more essential difference between genders, we will focus on resting-state functional connectivity and find out whether there exists the similar differences.

\subsection{Gender classification via functional connectivity}

In recent years, the machine learning models have become powerful tools for classification and have been widely used in different areas. The previous studies also show that the machine learning can be used for gender classification based on functional connectivity, and can achieve a high accuracy or AUC on both static functional connectivity\cite{Al_Zoubi2020-ij}\cite{Leming2021-on}\cite{Weis2020-cc}\cite{Zhang2018-fi} and dynamic functional connectivity\cite{Fan2020-ql}\cite{Menon2019-ef}\cite{Sen2021-ws}.

Some of the previous studies are shown in Table \ref{intro-previous}, which shows that for the gender classification, the past studies using machine learning methods from SVM to CNN, RNN can reach the accuracy and AUC both more than 65\% with the highest accuracy up to 94\%, depending on the dataset and methods used. These results show that there exists gender difference on functional connectivity, however, the nonlinearity of these models leads to a poor explainability and difficulty in analysis.

In this paper, we designed and implemented a model based on multiple hyperplanes, which is easier for analysis. The model is tested with both static and dynamic functional connectivity data computed from the Human Connectome Project (HCP) dataset. The accuracy and AUC are used as a standard measure, and the experiments are repeat for 150 times for avoiding flukes. We then use the LDA to analysis the results and evaluate the importance of each brain region in the gender classification task, i.e. to find out which brain regions have the most significant gender differences.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        Author                     & Method                             & Input & Result                                        \\
        \hline
        Obada Al Zoubi, et al.     & SVM                                & sFC   & \makecell{across sample AUC: $0.72 (\pm 0.2)$ \\  within sample AUC: $0.72 (\pm 0.16)$}       \\
        \hline
        Matthew Leming, et al.     & CNN                                & sFC   & \makecell{rsfMRI AUC: $0.89$                  \\ tfMRI AUC $0.77$}   \\
        \hline
        Susanne Weis, et al.       & SVM                                & sFC   & \makecell{avg ACC: $0.69$                     \\ max ACC: $0.75$} \\
        \hline
        Chao Zhang, et al.         & PLSR                               & sFC   & AUC: $0.93$, ACC: $0.85$
        \\
        \hline
        Liangwei Fan, et al.       & CNN \& LSTM                        & dFC   & AUC: $0.98$, ACC: $0.93 (\pm 0.02)$
        \\
        \hline
        Sreevalsan S Menon, et al. & Statistics                         & dFC
                                   & \makecell{Pearson dFC: ACC: $0.80$                                                         \\
        Partial sFC: ACC: $0.90$                                                                                                \\
            Pearson sFC: ACC: $0.68$}
        \\
        \hline
        Bhaskar Sen, et al.        & Random forest                      & dFC   & ACC: $0.94$                                   \\
        \hline
    \end{tabular}
    \caption{Some examples of previous studies which use machine learning models and functional connectivity to predict gender, where sFC represents the static functional connectivity and dFC represents the dynamic functional connectivity. All the data is rounded up to 2 decimal places.}
    \label{intro-previous}
\end{table}

\section{Materials and methods}

\subsection{Human Connectome Project (HCP)}

The Human Connectome Project (HCP) datasets\cite{Glasser2013-ha}\cite{Van_Essen2012-gc} is used in this paper to test the model. The HCP dataset has mapped the healthy human connectome by collecting and freely sharing neuroimaging and behavioural data from 1200 normal young adults, mostly aged 22-35, using a protocol that includes structural and functional magnetic resonance imaging (MRI, FMRI), diffusion tensor imaging (dMRI) at 3 Tesla (3T), and behavioural and genetic testing. Using vastly improved methods of data acquisition, analysis and sharing, the HCP dataset has provided the scientific community with data and discoveries that have greatly advanced our understanding of human brain structure, function and connectivity and their relationship to behaviour. It also provides a treasure trove of neuroimaging and behavioural data at an unprecedented level of detail. Currently, the HCP dataset is widely used to conduct research on the functional connectivity of the human brain.


\subsection{Preprocessing}

Our experimental data were taken from time series data from the HCP dataset, including the data with nodes 15, 25, and 50 (which means numbers of different brain regions), respectively, which from all 1003 subjects who performed four full rfMRI runs (for a total of 4800 time points). And the data is processed with following steps\cite{Filippini2009-so}\cite{Beckmann2004-jg}\cite{Smith2011-ki}\cite{Smith2013-gg}, where the first three steps have been done by the HCP dataset: (1) pre-process fMRI image data including spatial normalization, noise reduction, etc; (2) use group-ICA to decompose the brain regions; (3) For each brain region, compute the representative timeseries; (4) compute the functional connectivity via partial correlation.

An easy way to estimate the elements of the covariance matrix is to use the sliding window technique\cite{Allen2014-tl}. Given the number of nodes, the window size, the step size, and threshold parameters, a sliding window analysis is performed on the time series data for each subject. Subsequently, the window moves on the timeline and a new correlation coefficient is calculated at each point in time. In this way, we can dynamically evaluate the correlation changes between nodes based on time series data. This approach allows us to capture the structural properties of the data over time without the need for fixed global estimates. The sliding-window correlation at time $t$ is defined as follows:

$$
    \tilde\rho_t = \frac{\sum_{s=t}^{t+w-1} y_{1, s} y_{2, s}}{\sum_{s=t}^{t+w-1} y_{1, s}^2 \sum_{s=t}^{t+w-1} y_{2, s}^2}.
$$

According to this definition the correlation at time $t$ is based on $w$ future measurements of the time courses, from which we can get the dynamic functional connectivity.

\subsection{Models}
\label{sec-Models}

Different form the previous papers, we design a model classify the data with multiple hyperplanes. Specifically, given a dataset $\{(\mathbf{x}_i , y_i)\}_{i=1}^N$, we aims to find some vectors $\{\mathbf{w}_k\}_{k=1}^m$ and numbers $\{b_k\}_{k=1}^m$ such that for any given data $\mathbf{x}$ can be classificated via the tuple of distance $(\langle \mathbf{x}, \mathbf{w}_1 \rangle - b_1, dots, \langle \mathbf{x}, \mathbf{w}_m \rangle - b_m)$. In a simple case, for a input $\mathbf{x}_i$, we can check whether for all $j = 1, dots, m$, $\langle \mathbf{x}_i, \mathbf{w}_j \rangle - b_j gt.eq 0$ and split the input data ${\mathbf{x}_i}_{i=1}^n$ into two classes. Also, a nonlinear classifier like MLP can be used for classification.

In order to avoid flukes, the dataset is splited into training dataset(80\%) and test dataset(20\%), and repeat the experiment for 150 times, which implies an error of the results very likely to be lower than $1\%$ (the detailed proof can be find in appendix \ref{analysis-for-repetitions}).

Then we choose SVM as the baseline and implemented our model with CNN and MLP based on scikit-learn and PyTorch as Figure \ref{figure-model}. We set a 1-layer CNN model so that the weights of CNN correspond to $\mathbf{w}_i$ and $b_i$ and the channel of CNN corresponding to $m$, which is the number of hyperplanes (or features). Then a 2-layer MLP model will classify the features into two genders, which can be regard as a weakly nonlinear transfrom on the features.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./figure/method.png}
    \caption{The flowchart of method in \ref{sec-Models}. The weights of CNN correspond to $\mathbf{w}_i$ and $b_i$ in the model, and a MLP model is used for classification.}
    \label{figure-model}
\end{figure}

\subsubsection{SVM model}

The SVM model\cite{Vapnik1997-yy}\cite{Cortes1995-dg} is a supervised learning algorithm for classification and regression analysis, the core idea of which is to find an optimal hyperplane in the feature space to maximize the spacing between different classes. So we want to find the most suitable hyperplane to divide the genders.

Since it is hard to determine whether the brain network data is linearly separable before conducting experiments about SVM, we use both the linear SVM and the NuSVM model to train the brain network data respectively.

\subsubsection{CNN model}

The Convolutional Neural Networks (CNN) model is a class of feedforward neural networks with convolutional computation and deep structures. We choose the CNN model because CNN can automatically learn and extract complex features of data through its multi-layer convolution structure, and each layer can be seen as segmenting the data at different levels of abstraction, which is equivalent to using multiple hyperplanes to divide the data. And in the worst-case scenario, where all hyperplanes are the same, the model is linear SVM, and its results should be the same as SVM.

\section{Result}

\subsection{Preprocessing}

Some results of preprocessing is shown as Figure \ref{sample-dfc-c}, the entry $i,j$ of the heap map corresponding to the partial correlation between node $i,j$ and all the data are centered by the mean value. As for 15 node, there are significant differences in functional connectivity data across different regions. By contrast, when the number of nodes increases to 25, these gaps are remarkably narrowed. Further expanding to 50 nodes, the diagrams show nearly consistent colors across different regions, indicating a high degree of similarity in functional connectivity between different brain regions, which means stronger uniformity between different regions. Meanwhile the minimum, average and maximum variance of dynamic functional connectivity shown in Table \ref{var-dfc} also lead to the same conclusion.

\begin{figure}[H]
    \centering
    \subfloat[$N_{\text{node}} = 15$]{
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=15_id=100206/n_c_0.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=15_id=100206/n_c_6.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=15_id=100206/n_c_12.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=15_id=100206/n_c_18.jpg}
        \includegraphics[width=0.2175\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=15_id=100206/c_24.jpg}} \\
    \subfloat[$N_{\text{node}} = 25$]{
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=25_id=100206/n_c_0.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=25_id=100206/n_c_6.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=25_id=100206/n_c_12.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=25_id=100206/n_c_18.jpg}
        \includegraphics[width=0.2175\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=25_id=100206/c_24.jpg}} \\
    \subfloat[$N_{\text{node}} = 50$]{
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=50_id=100206/n_c_0.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=50_id=100206/n_c_6.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=50_id=100206/n_c_12.jpg}
        \includegraphics[width=0.18\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=50_id=100206/n_c_18.jpg}
        \includegraphics[width=0.2175\textwidth]{../Analysis/DFC/size=480_step=180_rho=0.1/node=50_id=100206/c_24.jpg}}
    \caption{Dynamic functional connectivity, where the each entry is centered by the mean value.}
    \label{sample-dfc-c}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        $N_{\text{node}}$ & min     & mean    & max     \\
        \hline
        $15$              & 5.76e-6 & 2.80e-5 & 1.99e-4 \\
        \hline
        $25$              & 2.82e-6 & 1.07e-5 & 6.07e-5 \\
        \hline
        $50$              & 1.63e-8 & 1.34e-6 & 4.90e-6 \\
        \hline
    \end{tabular}
    \caption{Minimum, average and maximum variance of the each entry of dynamic functional connectivity.}
    \label{var-dfc}
\end{table}

\subsection{SVM model}

Figure \ref{svm-results} shows the experimental results for SVM, which shows that the classification accuracy of the model rises with the increase of nodes of the data. Taking the maximum AUC in different nodes as examples, it is 87.56\% for 15 node, 92.02\% for 25 node, and 97.49\% for 50 node. These numerical results indicate that when the regional features are convergent, the classification accuracy will be correspondingly improved. Additionally, among all tests, the dynamic data of 15 nodes demonstrates the lowest accuracy, which is approximately at 69\%. This indicates that both dynamic and static functional connectivity data are linearly separable.

The appendix \ref{Ablation-study-for-SVM-model} shows more details about the results of SVM model, and from which we can infer that, when comparing the classification accuracy of dynamic data and static data under the same nodes, the performance of dynamic data is not better than that of static data. This might be attributed to some complex features that dynamic data takes so that it is difficult to extract all of them efficiently using single hyperplane.

\begin{figure}[H]
    \centering
    \subfloat[Linear SVM]{\includegraphics[width=0.5\textwidth]{../SVM/linear_0.1.jpg}}
    \subfloat[Nu-SVM]{\includegraphics[width=0.5\textwidth]{../SVM/nu_0.1.jpg}}
    \caption{Results of SVM model, where the 3 columns on the left of each subfigures shows the results of static functional connectivity, while the left shows the results of dynamic functional connectivity}
    \label{svm-results}
\end{figure}

\subsection{CNN model}

Figure \ref{CNN-results} illustrates the overall results of the data training by CNN. The first 6 columns present the classification results using the static functional connectivity and all frame data of dynamic functional connectivity, while the last 3 columns describe the results with one frame data that randomly selected from dyanmic functional connectivity. It is remarkable that the classification accuracy is significantly lower when using parts of frame data.

The appendix \ref{Ablation-study-for-CNN-model} shows detailed accuracy with all the frame data. In general, classification accuracy still grows with the increase of the number of nodes: for 15 nodes, the average AUC and maximum AUC are around 87\% and 92\% respectively; for 25 nodes, these values are around 93\% and 97\%; for 50 nodes, these values are around 97\% and 99\%. However, when comparing the results from data with the same nodes, we find that the number of channels and the parameter for dropout show little difference in accuracy and AUC. The differences in above conditions mainly affect the value of the lowest classification accuracy. To be more specific, when the number of channels increases or the dropout normalization is not used, the lowest value will be slightly higher than that of other conditions. And in most cases, the accuracy and AUC will increase as the number of channel increases, but not very significant. For example, for 50 nodes dynamic functional connectivity with no dropout, the mean accuracy increase from 87.99\% to 90.41\% and 91.22\% as the channel increase from 1 to 2 and 4, which means that the model can capture some more features with more hyperplanes, but most of the characteristics can be seperated by one hyperplane, i.e. linear separable.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../Result/bar_channel=4_dropout=0.1.jpg} \\
    \subfloat[test ACC]{\includegraphics[width=0.4\textwidth]{../Result/test_acc_box_channel=4_dropout=0.1.jpg}}
    \subfloat[test AUC]{\includegraphics[width=0.4\textwidth]{../Result/test_auc_box_channel=4_dropout=0.1.jpg}}
    \caption{Results of CNN model with dropout = 0.1 and channel = 4. The 3 columns on the left present the results with the static functional connectivity; the 3 columns in the middle present the results with all frame data of dynamic functional connectivity; the 3 columns on the right present the results with one frame data that randomly selected from dyanmic functional connectivity.}
    \label{CNN-results}
\end{figure}

\section{Analysis}

\subsection{Linear discriminant analysis (LDA)}

To gain a deeper understanding of the data distribution and find out which brain regions play important roles in classification, we processed the brain network data with linear discriminant analysis (LDA) \cite{Goldstein1976-aj}, which is used as a statistical method to find the optimal linear combination to maximise between-group variance and minimise within-group variance. Specifically, for a given dataset $\{\mathbf{x}_i, y_i\}_{i=1}^N$, the LDA method aims to find a vector pair $\mathbf{w}, \mathbf{c}$ such that the inner product $\langle \mathbf{x}_i  - \mathbf{c}, \mathbf{w} \rangle$ minimizes the interclass variance and maximizes the distance between the projected means of the classes.

Figure \ref{LDA-example-sfc} and Figure \ref{LDA-example-dfc} shows the distributions of static and dynamic functional connectivity with different nodes, from which we can gain the following conclusions: (1) there are overlapping parts in the data distribution of male and female under different nodes, and these regions may represent the common brain network characteristics or functional connectivity patterns of both genders; (2) the area of overlapping parts becomes smaller with the increase of the number of nodes, which supports the conclusions that more nodes lead to more higher accuracy and AUC in section 2; (3) there are outliers presents in both dynamic and static functional connectivity, with the dynamic functional connectivity exhibiting no fewer outliers than the static data, which might have negative impacts on the experimental results, thereby reducing the accuracy of gender classification especially using dynamic brain network data.

\begin{figure}[H]
    \centering
    \subfloat[$N_{\text{node}} = 15$]{
        \begin{minipage}[b]{0.3\textwidth}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=15_size=4800_step=4800_rho=0.1/hist_0.jpg}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=15_size=4800_step=4800_rho=0.1/box_0.jpg}
        \end{minipage}
    }
    \subfloat[$N_{\text{node}} = 25$]{
        \begin{minipage}[b]{0.3\textwidth}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=25_size=4800_step=4800_rho=0.1/hist_0.jpg}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=25_size=4800_step=4800_rho=0.1/box_0.jpg}
        \end{minipage}
    }
    \subfloat[$N_{\text{node}} = 50$]{
        \begin{minipage}[b]{0.3\textwidth}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=50_size=4800_step=4800_rho=0.1/hist_0.jpg}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=50_size=4800_step=4800_rho=0.1/box_0.jpg}
        \end{minipage}
    }
    \caption{The distribution of 1-dimension data given by LDA with static functional connectivity as input data.}
    \label{LDA-example-sfc}
\end{figure}

\begin{figure}[H]
    \centering
    \subfloat[$N_{\text{node}} = 15$]{
        \begin{minipage}[b]{0.3\textwidth}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=15_size=480_step=180_rho=0.1/hist.jpg}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=15_size=480_step=180_rho=0.1/box.jpg}
        \end{minipage}
    }
    \subfloat[$N_{\text{node}} = 25$]{
        \begin{minipage}[b]{0.3\textwidth}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=25_size=480_step=180_rho=0.1/hist.jpg}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=25_size=480_step=180_rho=0.1/box.jpg}
        \end{minipage}
    }
    \subfloat[$N_{\text{node}} = 50$]{
        \begin{minipage}[b]{0.3\textwidth}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=50_size=480_step=180_rho=0.1/hist.jpg}
            \includegraphics[width=1\textwidth]{../Analysis/LDA/node=50_size=480_step=180_rho=0.1/box.jpg}
        \end{minipage}
    }
    \caption{The distribution of 1-dimension data given by LDA with dynamic functional connectivity as input data.}
    \label{LDA-example-dfc}
\end{figure}

\subsection{Neuroscientiﬁc interpretations}

Through the above experiments and analysis, we can find several brain regions with the most significant gender differences. Specifically, denoted by $w_{ij} = w_{ji}$ the weight (particularly, average weight for dFC) for the partial correlation of node $i$ and $j$ given by the models, we sum up the absolute value of the weights for the node $i$, $w_i = \sum_{j=1}^{n} \vert w_{ij} \vert$, which represents how important the region is in the classification. Then the brain regions with corresponding value larger than the threshold will be regard as the most significant regions.

The most significant region for $N_{\text{node}} = 15, 25$ is shown as Figure \ref{msr-n-15} and Figure \ref{msr-n-25}, with the following conclusions: (1) the most significant region of static and dynamic functional connectivity are similar, which means that the differences in these regions are essential in gender classification; (2) the frontal lobe and the parietal lobe are the most significant, meanwhile the diencephalon, the temporal lobe and the occipital lobe also play a important role in gender classification; (3) these region of difference implies that the gender difference may lead to differences in emotion, memory, perception, etc., which is also shows in the previous psychology research\cite{skaalvik1994gender}\cite{soetanto2006there}\cite{wiesenfeld2005sex}\cite{chaplin2013gender}\cite{fischer2018gender}\cite{guillem2005gender}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d15.ica/0010.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d15.ica/0005.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d15.ica/0008.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d15.ica/0001.png}
    \caption{The most significant region for $N_{\text{node}} = 15$.}
    \label{msr-n-15}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d25.ica/0004.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d25.ica/0005.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d25.ica/0001.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d25.ica/0009.png} \\
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d25.ica/0007.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d25.ica/0024.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d25.ica/0017.png}
    \includegraphics[width=0.2\textwidth]{../Analysis/MIR/groupICA/groupICA_3T_HCP1200_MSMAll_d25.ica/0021.png}
    \caption{The most significant region for $N_{\text{node}} = 25$.}
    \label{msr-n-25}
\end{figure}

\section{Discussion}

In pre-processing step, the choices of size and moving step for sliding windows would make a big difference on the precision of dynamic functional connectivity data that we compute. To be more specific, a shorter window size would lead to better time resolution but poorer frequency resolution, while a wider window size is to the contrary\cite{Leiber2023-de}. Additionally, a larger moving step could reduce the complexity of computation but decrease the detection accuracy\cite{jiang2015flexible}. Consequently, it is important to balance both time and frequency resolution and enhance the capture efficiency of signal characteristics and overall trends for improvement of our experiments in the future. Toward this, employing Fourier analysis\cite{Mantini2007-sv} or wavelet analysis\cite{Medda2016-vh} might work. These 2 methods could analyse complex patterns from time series data with the former decomposing the periodic signal and the latter providing the local features of the signal in the time and frequency domains\cite{Guo2022-dk}.

Additionally, the experimental results for classification with 2 different models training reveal that the AUC of classification is slightly higher with the data trained by CNN than by SVM, while the accuracy rate remains at the same level between the two models. This might be attributed to redundant features extracted by CNN when training data, which means features from different convolutional kernels exhibit convergence.

To address this issue in the future, we might consider to set the coefficients of CNN to be orthogonal. On the one hand,this approach could ensure the unique features extracted from different convolutional kernels and reduce the correlation among features by Orthogonal Projection Loss (OPL)\cite{ranasinghe2021orthogonal}, which offers more significant differences among multiple classes and therefore improves the accuracy of classification. On the other hand, orthogonal initialization could keep the gradients stable during the back-propagation process by maintaining the orthogonality of the weight matrix and therefore alleviate the explosion and vanishing of gradients\cite{Achour2021-rl}, which accelerating the convergence rate of models and increasing the efficiency and performance of training.

Finally, the conclusion that both dynamic and static functional connectivity data are linearly separable bases on the results from 2 linear classifers that we use. But this idea exists some limitations. For example, if the data need to be partitioned to some non-linear target classes, or some complex features of data could not extracted by linear models efficiently. In these conditions, the non-linear classifer such as quadratic classifer would be utilized to partition such data in our future experiments since it could consider the inequality of the in-class covariance matrix and therefore the decision boundary is allowed to take a quadratic form\cite{Rasero2018-hi}, so as to better adapt to the complex structure in the data and partition data with higher efficiency.

\section{Conclusion}

Our results show that there exists gender difference in resting-state functional connectivity, which is linear separable and the accuracy and AUC of linear classifer can reach or even exceed the level of nonlinear classifiers in other papers. The coefficients we obtained also shows that the both for static and dynamic functional connectivity, some of the brain region, such as the frontal lobe and the parietal lobe, are significant in gender classification, which implies that the gender difference may lead to some essential differences in these region, and also the brain functions like emotion, memory, perception, etc..

\newpage

\bibliographystyle{unsrt}
\bibliography{reference.bib}
\addcontentsline{toc}{section}{References}

\newpage

\appendix
\renewcommand\thesection{\Alph{section}}

\section{Supplementary Material}

\subsection{Ablation study for SVM model}
\label{Ablation-study-for-SVM-model}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        Method    & Node & Data & min ACC/AUC   & mean ACC/AUC  & max ACC/AUC   \\
        \hline
        LinearSVM & 15   & sFC  & 0.7363/0.7369 & 0.8083/0.8078 & 0.8706/0.8756 \\
        \hline
        LinearSVM & 25   & sFC  & 0.8060/0.8059 & 0.8714/0.8708 & 0.9204/0.9202 \\
        \hline
        LinearSVM & 50   & sFC  & 0.8905/0.8905 & 0.9357/0.9357 & 0.9751/0.9749 \\
        \hline
        LinearSVM & 15   & dFC  & 0.6866/0.6919 & 0.7746/0.7733 & 0.8507/0.8534 \\
        \hline
        LinearSVM & 25   & dFC  & 0.7861/0.7874 & 0.8739/0.8730 & 0.9204/0.9206 \\
        \hline
        LinearSVM & 50   & dFC  & 0.8806/0.8813 & 0.9295/0.9300 & 0.9652/0.9666 \\
        \hline
        Nu-SVM    & 15   & sFC  & 0.7562/0.7571 & 0.8221/0.8219 & 0.8856/0.8847 \\
        \hline
        Nu-SVM    & 25   & sFC  & 0.8259/0.8257 & 0.8791/0.8782 & 0.9303/0.9302 \\
        \hline
        Nu-SVM    & 50   & sFC  & 0.8458/0.8458 & 0.9191/0.9194 & 0.9602/0.9608 \\
        \hline
        Nu-SVM    & 15   & dFC  & 0.7313/0.7324 & 0.8066/0.8056 & 0.8706/0.8674 \\
        \hline
        Nu-SVM    & 25   & dFC  & 0.8109/0.8121 & 0.8811/0.8802 & 0.9303/0.9296 \\
        \hline
        Nu-SVM    & 50   & dFC  & 0.8308/0.8300 & 0.9021/0.9022 & 0.9552/0.9579 \\
        \hline
    \end{tabular}
    \caption{Ablation study for SVM.}
\end{table}

\begin{figure}[H]
    \centering
    \subfloat[test ACC for LinearSVM]{\includegraphics[width=0.4\textwidth]{../SVM/acc_linear_0.1.jpg}}
    \subfloat[test AUC for LinearSVM]{\includegraphics[width=0.4\textwidth]{../SVM/auc_linear_0.1.jpg}} \\
    \subfloat[test ACC for NuSVM]{\includegraphics[width=0.4\textwidth]{../SVM/acc_nu_0.1.jpg}}
    \subfloat[test AUC for NuSVM]{\includegraphics[width=0.4\textwidth]{../SVM/auc_nu_0.1.jpg}} \\
    \caption{Results of SVM.}
\end{figure}

\subsection{Ablation study for CNN model}
\label{Ablation-study-for-CNN-model}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        Data & Dropout & Channel & min ACC/AUC   & mean ACC/AUC  & max ACC/AUC   \\
        \hline
        sFC  & 0.0     & 1       & 0.5224/0.8108 & 0.7957/0.8855 & 0.8706/0.9307 \\
        \hline
        sFC  & 0.0     & 2       & 0.7164/0.8273 & 0.8001/0.8876 & 0.8756/0.9281 \\
        \hline
        sFC  & 0.0     & 4       & 0.7363/0.8189 & 0.7988/0.8863 & 0.8607/0.9337 \\
        \hline
        sFC  & 0.1     & 1       & 0.5174/0.8041 & 0.7952/0.8870 & 0.8756/0.9355 \\
        \hline
        sFC  & 0.1     & 2       & 0.7164/0.8318 & 0.7986/0.8885 & 0.8756/0.9294 \\
        \hline
        sFC  & 0.1     & 4       & 0.7313/0.8276 & 0.8038/0.8911 & 0.8607/0.9317 \\
        \hline
        dFC  & 0.0     & 1       & 0.5871/0.7160 & 0.7737/0.8670 & 0.8557/0.9216 \\
        \hline
        dFC  & 0.0     & 2       & 0.6915/0.7824 & 0.7811/0.8630 & 0.8507/0.9209 \\
        \hline
        dFC  & 0.0     & 4       & 0.7015/0.8028 & 0.7787/0.8584 & 0.8408/0.9148 \\
        \hline
        dFC  & 0.1     & 1       & 0.5522/0.7140 & 0.7735/0.8656 & 0.8458/0.9209 \\
        \hline
        dFC  & 0.1     & 2       & 0.6617/0.7942 & 0.7771/0.8692 & 0.8408/0.9110 \\
        \hline
        dFC  & 0.1     & 4       & 0.7164/0.7987 & 0.7813/0.8666 & 0.8408/0.9171 \\
        \hline
    \end{tabular}
    \caption{Ablation study for $N_{\text{node}} = 15$.}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        Data & Dropout & Channel & min ACC/AUC   & mean ACC/AUC  & max ACC/AUC   \\
        \hline
        sFC  & 0.0     & 1       & 0.5075/0.7475 & 0.8462/0.9265 & 0.9104/0.9634 \\
        \hline
        sFC  & 0.0     & 2       & 0.7662/0.8731 & 0.8470/0.9225 & 0.9104/0.9599 \\
        \hline
        sFC  & 0.0     & 4       & 0.7512/0.8650 & 0.8468/0.9220 & 0.9055/0.9603 \\
        \hline
        sFC  & 0.1     & 1       & 0.5124/0.7431 & 0.8547/0.9356 & 0.9154/0.9688 \\
        \hline
        sFC  & 0.1     & 2       & 0.7711/0.8598 & 0.8581/0.9358 & 0.9254/0.9728 \\
        \hline
        sFC  & 0.1     & 4       & 0.7711/0.8730 & 0.8562/0.9339 & 0.9104/0.9638 \\
        \hline
        dFC  & 0.0     & 1       & 0.6269/0.7168 & 0.8450/0.9338 & 0.9303/0.9788 \\
        \hline
        dFC  & 0.0     & 2       & 0.7463/0.8662 & 0.8594/0.9416 & 0.9254/0.9787 \\
        \hline
        dFC  & 0.0     & 4       & 0.7960/0.9130 & 0.8672/0.9437 & 0.9154/0.9783 \\
        \hline
        dFC  & 0.1     & 1       & 0.5771/0.6996 & 0.8391/0.9319 & 0.9254/0.9753 \\
        \hline
        dFC  & 0.1     & 2       & 0.7612/0.8584 & 0.8618/0.9441 & 0.9204/0.9752 \\
        \hline
        dFC  & 0.1     & 4       & 0.7264/0.8902 & 0.8606/0.9426 & 0.9104/0.9739 \\
        \hline
    \end{tabular}
    \caption{Ablation study for $N_{\text{node}} = 25$.}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        Data & Dropout & Channel & min ACC/AUC   & mean ACC/AUC  & max ACC/AUC   \\
        \hline
        sFC  & 0.0     & 1       & 0.5572/0.7721 & 0.9015/0.9689 & 0.9602/0.9947 \\
        \hline
        sFC  & 0.0     & 2       & 0.7512/0.8462 & 0.9218/0.9762 & 0.9701/0.9941 \\
        \hline
        sFC  & 0.0     & 4       & 0.8856/0.9589 & 0.9248/0.9779 & 0.9602/0.9938 \\
        \hline
        sFC  & 0.1     & 1       & 0.5124/0.7691 & 0.8960/0.9684 & 0.9652/0.9952 \\
        \hline
        sFC  & 0.1     & 2       & 0.7363/0.8335 & 0.9147/0.9746 & 0.9652/0.9947 \\
        \hline
        sFC  & 0.1     & 4       & 0.8358/0.9562 & 0.9178/0.9778 & 0.9652/0.9940 \\
        \hline
        dFC  & 0.0     & 1       & 0.6766/0.8767 & 0.8799/0.9689 & 0.9552/0.9924 \\
        \hline
        dFC  & 0.0     & 2       & 0.7711/0.9366 & 0.9041/0.9733 & 0.9552/0.9917 \\
        \hline
        dFC  & 0.0     & 4       & 0.8507/0.9543 & 0.9122/0.9766 & 0.9602/0.9946 \\
        \hline
        dFC  & 0.1     & 1       & 0.7363/0.8511 & 0.8945/0.9714 & 0.9602/0.9940 \\
        \hline
        dFC  & 0.1     & 2       & 0.8109/0.8966 & 0.9027/0.9716 & 0.9552/0.9925 \\
        \hline
        dFC  & 0.1     & 4       & 0.7711/0.9128 & 0.9040/0.9713 & 0.9552/0.9930 \\
        \hline
    \end{tabular}
    \caption{Ablation study for $N_{\text{node}} = 50$.}
\end{table}

\begin{figure}[H]
    \centering
    \subfloat[test ACC with dropout=0.0]{\includegraphics[width=0.4\textwidth]{../Result/test_acc_box_channel=1_dropout=0.0.jpg}}
    \subfloat[test AUC with dropout=0.0]{\includegraphics[width=0.4\textwidth]{../Result/test_auc_box_channel=1_dropout=0.0.jpg}} \\
    \subfloat[test ACC with dropout=0.1]{\includegraphics[width=0.4\textwidth]{../Result/test_acc_box_channel=1_dropout=0.1.jpg}}
    \subfloat[test AUC with dropout=0.1]{\includegraphics[width=0.4\textwidth]{../Result/test_auc_box_channel=1_dropout=0.1.jpg}}
    \caption{Results of CNN model with channel = 1.}
    % \label{CNN-results-3}
\end{figure}

\begin{figure}[H]
    \centering
    \subfloat[test ACC with dropout=0.0]{\includegraphics[width=0.4\textwidth]{../Result/test_acc_box_channel=2_dropout=0.0.jpg}}
    \subfloat[test AUC with dropout=0.0]{\includegraphics[width=0.4\textwidth]{../Result/test_auc_box_channel=2_dropout=0.0.jpg}} \\
    \subfloat[test ACC with dropout=0.1]{\includegraphics[width=0.4\textwidth]{../Result/test_acc_box_channel=2_dropout=0.1.jpg}}
    \subfloat[test AUC with dropout=0.1]{\includegraphics[width=0.4\textwidth]{../Result/test_auc_box_channel=2_dropout=0.1.jpg}}
    \caption{Results of CNN model with channel = 2.}
    % \label{CNN-results-3}
\end{figure}

\begin{figure}[H]
    \centering
    \subfloat[test ACC with dropout=0.0]{\includegraphics[width=0.4\textwidth]{../Result/test_acc_box_channel=4_dropout=0.0.jpg}}
    \subfloat[test AUC with dropout=0.0]{\includegraphics[width=0.4\textwidth]{../Result/test_auc_box_channel=4_dropout=0.0.jpg}} \\
    \subfloat[test ACC with dropout=0.1]{\includegraphics[width=0.4\textwidth]{../Result/test_acc_box_channel=4_dropout=0.1.jpg}}
    \subfloat[test AUC with dropout=0.1]{\includegraphics[width=0.4\textwidth]{../Result/test_auc_box_channel=4_dropout=0.1.jpg}}
    \caption{Results of CNN model with channel = 4.}
    % \label{CNN-results-3}
\end{figure}

\subsection{Analysis for repetitions}
\label{analysis-for-repetitions}

There are multiple choise for repetition times, e.g., in some article, this number is set to $300$\cite{Leming2021-on}. Thus is is neccessary to analysis how this parameter affect the result.

Assume that the results (AUC or ACC) $\{X_i\}_{i=1}^n$ for different test are independent and identically distributed (i.i.d.) with mean value $\mu$ and variance $\sigma^2$, then from central limit theorem

$$
    Y_n = \frac{\sum_{i=1}^n X_i - n \mu}{\sqrt{n} \sigma} \xrightarrow{D} N(0, 1).
$$

Thus for all $\varepsilon > 0$,

$$
    P\left(\vert \bar{X}_i - \mu \vert \leq \frac{\sigma \varepsilon}{\sqrt{n}}\right) = P(\vert Y_n - E(Y_n) \vert \leq \varepsilon) = \varPhi(\varepsilon) - \varPhi(-\varepsilon),
$$

where $\varPhi(x)$ is the cumulative distribution function of the standard normal distribution.

We compute the variance of samples $\sigma \leq \sqrt{0.007} \leq 0.1$, which implies that if choose $\varepsilon = \sqrt{n} / \delta$, then

$$
    P\left(\vert (\bar{X}_i - \mu)\vert \leq \frac{0.1}{\delta}\right) \geq P\left(\vert \bar{X}_i - \mu \vert \leq \frac{\sigma}{\delta}\right) = \varPhi\left(\frac{\sqrt{n}}{\delta}\right) - \varPhi\left(-\frac{\sqrt{n}}{\delta}\right).
$$

Then for $n = 150$, the result is shown as Table \ref{table-a-as-repetitions}, which implies that the results can reaches an error lower than $1\%$.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|}
        \hline
        $\delta = 5$    & $P(\vert \bar{X}_i - \mu \vert \leq 0.02) \geq 0.9857$    \\
        \hline
        $\delta = 8$    & $P(\vert \bar{X}_i - \mu \vert \leq 0.0125) \geq 0.8742$  \\
        \hline
        $\delta = 10$   & $P(\vert \bar{X}_i - \mu \vert \leq 0.01) \geq 0.7793$    \\
        \hline
        $\delta = 12.5$ & $P(\vert \bar{X}_i - \mu \vert \leq 0.008) \geq 0.6728$   \\
        \hline
        $\delta = 16$   & $P(\vert \bar{X}_i - \mu \vert \leq 0.00625) \geq 0.5560$ \\
        \hline
        $\delta = 20$   & $P(\vert \bar{X}_i - \mu \vert \leq 0.005) \geq 0.4597$   \\
        \hline
    \end{tabular}
    \caption{Probability of errors.}
    \label{table-a-as-repetitions}
\end{table}

\end{document}